{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDpLfel2o9vF",
        "outputId": "463dcd34-dc4f-4b2c-9477-34729c060c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated dataset with selected moods saved at: /content/music_moods_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "merged_dataset_path = '/content/merged_dataset.csv'\n",
        "merged_data = pd.read_csv(merged_dataset_path)\n",
        "\n",
        "# Remove the 'target' column which was the hit part\n",
        "if 'target' in merged_data.columns:\n",
        "    merged_data = merged_data.drop(columns=['target'])\n",
        "\n",
        "# Define a function to assign moods based on audio features\n",
        "def assign_selected_moods(row):\n",
        "    mood_scores = {\n",
        "        'happy': (row['valence'] > 0.7) + (row['danceability'] > 0.7) + (row['mode'] == 1),\n",
        "        'sad': (row['valence'] < 0.3) + (row['energy'] < 0.4) + (row['mode'] == 0),\n",
        "        'angry': (row['energy'] > 0.8) + (row['valence'] < 0.3) + (row['loudness'] > -5),\n",
        "        'fear': (row['valence'] < 0.3) + (row['loudness'] > -10) + (row['tempo'] > 150),\n",
        "        'surprise': (row['energy'] > 0.7) + (row['tempo'] > 140) + (0.4 < row['valence'] < 0.7)\n",
        "    }\n",
        "    # Select the mood with the highest score\n",
        "    return max(mood_scores, key=mood_scores.get)\n",
        "\n",
        "# Apply the function to assign moods to the dataset\n",
        "merged_data['mood'] = merged_data.apply(assign_selected_moods, axis=1)\n",
        "\n",
        "# Save the updated dataset with the selected moods\n",
        "selected_moods_dataset_path = '/content/music_moods_dataset.csv'\n",
        "merged_data.to_csv(selected_moods_dataset_path, index=False)\n",
        "\n",
        "# Print the path to the updated dataset\n",
        "print(f\"Updated dataset with selected moods saved at: {selected_moods_dataset_path}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Why These Values?**\n",
        "The thresholds for these features are based on general psychological and music theory correlations between audio properties and human emotional responses:\n",
        "\n",
        "#### **Happy**\n",
        "- **Valence > 0.7**: High positivity indicates happiness.  \n",
        "- **Danceability > 0.7**: A strong rhythm and groove are often associated with joyful moods.  \n",
        "- **Mode == 1**: Major keys are conventionally perceived as happy.\n",
        "\n",
        "#### **Sad**\n",
        "- **Valence < 0.3**: Low positivity reflects sadness.  \n",
        "- **Energy < 0.4**: Low energy matches the subdued nature of sadness.  \n",
        "- **Mode == 0**: Minor keys typically evoke melancholic feelings.\n",
        "\n",
        "#### **Angry**\n",
        "- **Energy > 0.8**: High intensity matches the aggressive nature of anger.  \n",
        "- **Valence < 0.3**: Negative emotions like anger correlate with low positivity.  \n",
        "- **Loudness > -5**: High loudness can represent intensity and aggression.\n",
        "\n",
        "#### **Fear**\n",
        "- **Valence < 0.3**: Negative emotion indicates fear.  \n",
        "- **Loudness > -10**: Moderate loudness adds to the sense of alarm.  \n",
        "- **Tempo > 150**: Faster tempos are often associated with urgency or fear.\n",
        "\n",
        "#### **Surprise**\n",
        "- **Energy > 0.7**: High energy reflects the excitement or unpredictability of surprise.  \n",
        "- **Tempo > 140**: Fast tempos evoke a sense of movement and action, often surprising.  \n",
        "- **0.4 < Valence < 0.7**: A balance between positivity and negativity suggests an ambiguous or unexpected emotional tone.\n",
        "\n",
        "---\n",
        "\n",
        "### **How the Moods Are Assigned**\n",
        "1. Each mood is scored by checking whether specific conditions are met for the audio features.\n",
        "   - For instance, a \"happy\" mood adds 1 point for each of these:\n",
        "     - **Valence > 0.7**, **Danceability > 0.7**, and **Mode == 1**.\n",
        "\n",
        "2. The mood with the **highest score** for a track is selected as the primary mood.\n",
        "\n",
        "---\n",
        "\n",
        "### **Limitations**\n",
        "- These thresholds are approximations and may not perfectly capture all moods.\n",
        "- Cultural and personal differences in music perception mean some users might interpret the same track differently.\n",
        "- The fixed thresholds (e.g., `valence > 0.7`) are simplistic and could be adjusted for specific datasets or preferences.\n",
        "\n",
        "\n",
        "* Adjusting these thresholds with labeled data could improve mood classification accuracy."
      ],
      "metadata": {
        "id": "81BgMruc1ZLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the songs were classified into five moods (happy, sad, angry, fear, surprise) as\n",
        "mentioned above as to why those. We mapped these to moods based on the ideas in the\n",
        "following papers and previous research (which is linked below) linking audio features to\n",
        "emotions:\n",
        "1. https://kratichoudhary258.medium.com/music-mood-classification-relativity-to-\n",
        "music-therapy-7c44250c45dc\n",
        "2. https://sites.tufts.edu/eeseniordesignhandbook/2015/music-mood-classification/\n",
        "3. https://mct-master.github.io/machine-learning/2020/09/20/Music-Mood-\n",
        "Classifier.html\n",
        "\n",
        "\n",
        "The main idea that we took from this research is that we can use audio features such as\n",
        "valence and tempo and energy, and more to be able to roughly estimate and map the\n",
        "mood of the song, and although this method is not perfect, with more time and resources\n",
        "such as Librosa to get the feature extractions of each song and use those to classify mood,\n",
        "this is sufficient (for now) for the project even if it is not perfect.\n",
        "\n",
        "\n",
        "### Conclusion:\n",
        "These papers discuss the general ideas which we took to estable the relationship between audio features like valence, energy, tempo, etc., and the emotional responses they elicit."
      ],
      "metadata": {
        "id": "RuRMrI9A1w13"
      }
    }
  ]
}